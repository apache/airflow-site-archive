# Licensed to the Apache Software Foundation (ASF) under one
# or more contributor license agreements.  See the NOTICE file
# distributed with this work for additional information
# regarding copyright ownership.  The ASF licenses this file
# to you under the Apache License, Version 2.0 (the
# "License"); you may not use this file except in compliance
# with the License.  You may obtain a copy of the License at
#
#   http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing,
# software distributed under the License is distributed on an
# "AS IS" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
# KIND, either express or implied.  See the License for the
# specific language governing permissions and limitations
# under the License.
#
---
name: Sync GitHub to S3
on: # yamllint disable-line rule:truthy
  workflow_dispatch:
    inputs:
      destination-location:
        description: "The destination location in S3"
        required: false
        default: "s3://live-docs-airflow-apache-org/docs/"
        type: string
      document-folder:
        description: "Provide any specific package document folder to sync"
        required: false
        default: ""
        type: string
      sync-type:
        description: "Perform a full sync or just sync the last commit"
        required: false
        default: "single_commit"
        type: choice
        options:
          - single_commit
          - full_sync
      commit-sha:
        description: "If specified, commit SHA used for single_commit (default is latest commit)"
        required: false
        default: ""
        type: string
      processes:
        description: "Number of processes to use for syncing"
        required: false
        default: "8"
        type: string
jobs:
  github-to-s3:
    name: GitHub to S3
    runs-on: ubuntu-latest
    steps:
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - uses: actions/checkout@v4
        # Checkout only workflow and scripts directory to run scripts from
        with:
          sparse-checkout: |
            .github
            scripts

      - name: Install AWS CLI v2
        run: |
          curl "https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip" -o /tmp/awscliv2.zip
          unzip -q /tmp/awscliv2.zip -d /tmp
          rm /tmp/awscliv2.zip
          sudo /tmp/aws/install --update
          rm -rf /tmp/aws/

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@010d0da01d0b5a38af31e9c3470dbfdabdecca3a  # v4.0.1
        with:
          aws-access-key-id: ${{ secrets.DOCS_AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.DOCS_AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-2

      - name: Remove some stuff we don't need
        run: |
          sudo rm -rf /usr/share/dotnet
          sudo rm -rf /opt/ghc
          sudo rm -rf "/usr/local/share/boost"
          sudo rm -rf "$AGENT_TOOLSDIRECTORY"

      - name: "Checkout ${{ github.ref }} ( ${{ github.sha }} ) for scripts"
        uses: actions/checkout@v4
        # Checkout only workflow and scripts directory to run scripts from
        with:
          sparse-checkout: |
            .github
            scripts

      - name: Create /mnt/airflow-site-archive directory
        run: |
          sudo mkdir -pv /mnt/airflow-site-archive
          sudo chown -R "${USER}" /mnt/airflow-site-archive
          ln -v -s /mnt/airflow-site-archive ./airflow-site-archive

      - name: Pre-process docs folder
        env:
          DOCUMENTS_FOLDER: ${{ inputs.document-folder }}
        id: docs-folder
        run: |
          echo "docs-folder=${DOCUMENTS_FOLDER}" >> ${GITHUB_OUTPUT}
          if [[ "${DOCUMENTS_FOLDER}" != "" ]]; then
            echo "Preprocessing docs folder: ${DOCUMENTS_FOLDER}"
            if [[ "${DOCUMENTS_FOLDER}" != apache-airflow-providers* ]]; then
              echo "docs-folder=apache-airflow-providers-${DOCUMENTS_FOLDER/./-}" >> ${GITHUB_OUTPUT}
            fi
          fi

      - name: >
          Checkout (${{  inputs.commit-sha || github.sha }}) to /mnt/airflow-site-archive
          with docs: ${{ steps.docs-folder.outputs.docs-folder }}"
        uses: actions/checkout@v4
        with:
          path: ./airflow-site-archive
          fetch-depth: 2
          sparse-checkout: |
            docs-archive/${{ steps.docs-folder.outputs.docs-folder }}
          ref: ${{ inputs.commit-sha || github.sha }}

      - name: >
          Syncing ${{ inputs.commit-sha || github.sha }}:
          ${{ inputs.sync-type }} ${{ steps.docs-folder.outputs.docs-folder }}"
        env:
          COMMIT_SHA: ${{ inputs.commit-sha || github.sha }}
          SYNC_TYPE: ${{ inputs.sync-type }}
          PROCESSES: ${{ inputs.processes }}
          DOCUMENTS_FOLDER: ${{ steps.docs-folder.outputs.docs-folder }}
          DESTINATION_LOCATION: ${{ inputs.destination-location }}
        run: |
          if [[ "${SYNC_TYPE}" == "single_commit" ]]; then
            echo "Syncing ${COMMIT_SHA}"
          else
            echo "Syncing whole repo"
          fi
          ls -la /mnt/airflow-site-archive/*
          python3 -m pip install uv
          uv run ./scripts/github_to_s3.py \
            --bucket-path ${DESTINATION_LOCATION} \
            --local-path /mnt/airflow-site-archive/docs-archive \
            --document-folder "${DOCUMENTS_FOLDER}" \
            --commit-sha ${COMMIT_SHA} --sync-type ${SYNC_TYPE} \
            --processes ${PROCESSES}
